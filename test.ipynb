{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    AIMessage, \n",
    "    BaseMessage,\n",
    "    ToolMessage\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, List\n",
    "from agents.prompt import (\n",
    "    SYSTEM_PROMPT,\n",
    "    SERVICE_PROMPT\n",
    ")\n",
    "from tools import (\n",
    "    all_tools, \n",
    "    set_customer_data,\n",
    "    get_customer_data\n",
    ")\n",
    "import functools\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\", \n",
    "    temperature=0, \n",
    "    top_p=0, \n",
    "    )\n",
    "\n",
    "## Define state ------------------------------------------------------------------------\n",
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    chat_history: List[BaseMessage]\n",
    "    sender: str\n",
    "\n",
    "\n",
    "def __bind(llm, tools:list, agnet_prompt:str):\n",
    "    \"\"\" create llm with SYSTEM_PROMPT and agent prompt, bind tools, then return agent.\n",
    "    \"\"\"\n",
    "    ## create agents with prompt and tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                SYSTEM_PROMPT,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=agnet_prompt)\n",
    "    prompt = prompt.partial(agent_names=agent_names)\n",
    "    \n",
    "    # return llm without tools\n",
    "    if tools:\n",
    "        prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "        #llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "        llm = llm.bind_tools(tools)\n",
    "    else:\n",
    "        prompt = prompt.partial(tool_names=\"<no available tools for you>\")\n",
    "    \n",
    "    agent = prompt | llm\n",
    "    return agent\n",
    "\n",
    "\n",
    "def service_node_build(state:AgentState, name, tools) -> AgentState:\n",
    "    llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\", \n",
    "    temperature=0, \n",
    "    top_p=0, \n",
    "    )\n",
    "    \n",
    "    agent = __bind(llm, tools, SERVICE_PROMPT)\n",
    "    \n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if not isinstance(result, ToolMessage):\n",
    "        chat_history = state.get('chat_history')\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        \"chat_history\" : chat_history,\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n",
    "\n",
    "\n",
    "agent_names = ['service']\n",
    "\n",
    "agent_nodes = {name:None for name in agent_names}\n",
    "\n",
    "agent_nodes['service'] = functools.partial(service_node_build, name='service', tools=all_tools)\n",
    "\n",
    "# agent_nodes['service']({'chat_history':[], 'messages':[]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
