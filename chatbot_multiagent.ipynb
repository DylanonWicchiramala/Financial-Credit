{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env ------------------------------------------------------------------------\n",
    "import functools\n",
    "import os\n",
    "import uuid\n",
    "import database.chat_history\n",
    "import database.customer\n",
    "import utils\n",
    "import re\n",
    "\n",
    "utils.load_env()\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"false\"\n",
    "\n",
    "\n",
    "# debug ------------------------------------------------------------------\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "set_verbose(False)\n",
    "set_debug(False)\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from agents import(\n",
    "    AgentState,\n",
    "    agents_metadata,\n",
    "    agent_names\n",
    ")\n",
    "from functools import partial\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from tools import get_tools_output, all_tools, set_current_user_id\n",
    "import database\n",
    "## Define Tool Node\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import Literal, Optional, TypedDict\n",
    "\n",
    "\n",
    "class BotConfig(TypedDict):\n",
    "    keep_chat_history:Optional[bool]\n",
    "    return_reference:Optional[bool]\n",
    "    verbose:Optional[bool]\n",
    "    recursion_limit:Optional[int]\n",
    "    thread_id: Optional[uuid.UUID]\n",
    "    \n",
    "\n",
    "class AgentBot:\n",
    "    tool_node:ToolNode\n",
    "    agent_names:list[str]\n",
    "    agents:dict[str, dict[str, partial]]\n",
    "    workflow: StateGraph\n",
    "    config:BotConfig = BotConfig({\n",
    "        'keep_chat_history': False,\n",
    "        'return_reference': False,\n",
    "        'verbose': False,\n",
    "        'recursion_limit': 20,\n",
    "        'thread_id': uuid.uuid4(),\n",
    "    })\n",
    "    \n",
    "    def __init__(self, **config:BotConfig):\n",
    "        self.tool_node = ToolNode(all_tools)\n",
    "        self.agent_names = list(agents_metadata.keys())\n",
    "        self.agents = agents_metadata\n",
    "        self.config.update(**config)\n",
    "        self.create_workflow()\n",
    "                \n",
    "        \n",
    "    def __with_debug_command(self, func):\n",
    "        def __convert_input_value(input_config_value: str):\n",
    "            # Check if input is a boolean\n",
    "            if input_config_value.lower() == \"false\":\n",
    "                return False\n",
    "            elif input_config_value.lower() == \"true\":\n",
    "                return True\n",
    "            \n",
    "            # Check if input is an integer\n",
    "            try:\n",
    "                int_value = int(input_config_value)\n",
    "                return int_value\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            # Check if input is a float\n",
    "            try:\n",
    "                float_value = float(input_config_value)\n",
    "                return float_value\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            # If none of the above, return the original string\n",
    "            return input_config_value\n",
    "        \n",
    "        @functools.wraps(func)  # Preserve the original function's metadata\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            user_input = args[0]\n",
    "            user_id = kwargs['user_id']\n",
    "            \n",
    "            if not re.search(r\"//\", user_input):\n",
    "                return func(*args, **kwargs)\n",
    "                \n",
    "            if re.search(r\"//reset\", user_input):\n",
    "                database.customer.delete(user_id=\"test\")\n",
    "                database.chat_history.delete(user_id=user_id)\n",
    "                database.customer.update({\n",
    "                    \"name\":\"สมชาย สายชม\",\n",
    "                },user_id=user_id)\n",
    "                return f\"user data and chat history have been reset.\"\n",
    "            \n",
    "            if re.search(r\"//delete chat history\", user_input):\n",
    "                o = database.chat_history.delete(user_id=user_id)\n",
    "                return f\"chat history of this user have been deleted.\"\n",
    "            \n",
    "            if re.search(r\"//get chat history\", user_input):\n",
    "                history = database.chat_history.get_str(user_id=user_id, chat_history=[])\n",
    "                nl = \"\\n\"\n",
    "                return f\"chat history: \\n{nl.join(history)}\"\n",
    "                \n",
    "            if re.search(r\"//get user data\", user_input):\n",
    "                user_data = database.customer.get(user_id=user_id)\n",
    "                return f\"user data: \\n{user_data}\"\n",
    "                \n",
    "            if re.search(r\"//debug\", user_input):\n",
    "                user_input = re.sub(r\"//debug\", '', user_input)\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    return f\"error: {e}\"\n",
    "            \n",
    "            for configkey in self.config.keys():\n",
    "                if re.search(r\"//{configkey} ?= ?\".format(configkey=configkey), user_input):\n",
    "                    input_config_value = re.sub(r\"//{configkey} ?= ?\".format(configkey=configkey), '', user_input)\n",
    "                    self.config[configkey] = __convert_input_value(input_config_value)\n",
    "                    return f\"set config: {configkey} to {input_config_value}\"\n",
    "            \n",
    "        return wrapper\n",
    "    \n",
    "    \n",
    "    def create_workflow(self):\n",
    "        def router(state) -> Literal[\"call_tool\", \"continue\", \"__end__\"]:\n",
    "            # This is the router\n",
    "            messages = state[\"messages\"]\n",
    "            last_message = messages[-1]\n",
    "            if \"FINALANSWER\" in last_message.content:\n",
    "                return \"__end__\"\n",
    "            if last_message.tool_calls:\n",
    "                # The previous agent is invoking a tool\n",
    "                return \"call_tool\"\n",
    "            else:\n",
    "                return \"continue\"\n",
    "        \n",
    "        workflow = StateGraph(AgentState)\n",
    "\n",
    "        # add agent nodes\n",
    "        for name, value in self.agents.items():\n",
    "            workflow.add_node(name, value['node'])\n",
    "            \n",
    "        workflow.add_node(\"call_tool\", self.tool_node)\n",
    "\n",
    "        workflow.add_conditional_edges(\n",
    "            \"service\",\n",
    "            router,\n",
    "            {\n",
    "                \"call_tool\": \"call_tool\",\n",
    "                \"__end__\": END,\n",
    "                \"continue\": END, \n",
    "                }\n",
    "        )\n",
    "\n",
    "        workflow.add_conditional_edges(\n",
    "            \"call_tool\",\n",
    "            # Each agent node updates the 'sender' field\n",
    "            # the tool calling node does not, meaning\n",
    "            # this edge will route back to the original agent\n",
    "            # who invoked the tool\n",
    "            lambda x: x[\"sender\"],\n",
    "            {name:name for name in agent_names},\n",
    "        )\n",
    "\n",
    "        workflow.add_edge(START, \"service\")\n",
    "        \n",
    "        self.workflow = workflow\n",
    "        \n",
    "        return self.workflow\n",
    "\n",
    "\n",
    "    def submit_user_message(\n",
    "        self,\n",
    "        user_input:str, \n",
    "        user_id:str=\"test\", \n",
    "        ) -> str:\n",
    "        # set_current_user_id(user_id)\n",
    "        chat_history = database.chat_history.get(user_id=user_id) if self.config['keep_chat_history'] else []\n",
    "        chat_history = chat_history[-8:]\n",
    "        \n",
    "        # memory only keep chat history only along agents.\n",
    "        # internal_level_memory = MemorySaver()\n",
    "        # graph = workflow.compile(checkpointer=internal_level_memory)\n",
    "        \n",
    "        graph = self.workflow.compile()\n",
    "\n",
    "        events = graph.stream(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    HumanMessage(\n",
    "                        user_input\n",
    "                    )\n",
    "                ],\n",
    "                \"chat_history\": chat_history\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": self.config['recursion_limit'], \"thread_id\":self.config['thread_id']},\n",
    "        )\n",
    "        \n",
    "        for e in events:\n",
    "            a = list(e.items())[0]\n",
    "            if self.config['verbose']:\n",
    "                a[1]['messages'][0].pretty_print()\n",
    "        \n",
    "        response = a[1]\n",
    "        \n",
    "        response = response[\"messages\"][0].content\n",
    "        response = utils.format_bot_response(response, markdown=True)\n",
    "        \n",
    "        if self.config['keep_chat_history']:\n",
    "            chat_history = database.chat_history.insert(bot_message=response, human_message=user_input, user_id=user_id)\n",
    "        \n",
    "        if self.config['return_reference']:\n",
    "            return response, get_tools_output()\n",
    "        else:\n",
    "            return response\n",
    "        \n",
    "        \n",
    "    async def asubmit_user_message(\n",
    "        self,\n",
    "        user_input:str, \n",
    "        user_id:str=\"test\", \n",
    "        ) -> str:\n",
    "        # set_current_user_id(user_id)\n",
    "        chat_history = database.chat_history.get(user_id=user_id) if self.config['keep_chat_history'] else []\n",
    "        chat_history = chat_history[-8:]\n",
    "        \n",
    "        # memory only keep chat history only along agents.\n",
    "        # internal_level_memory = MemorySaver()\n",
    "        # graph = workflow.compile(checkpointer=internal_level_memory)\n",
    "        \n",
    "        graph = self.workflow.compile()\n",
    "\n",
    "        events = graph.astream(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    HumanMessage(\n",
    "                        user_input\n",
    "                    )\n",
    "                ],\n",
    "                \"chat_history\": chat_history\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": self.config['recursion_limit'], \"thread_id\":self.config['thread_id']},\n",
    "            stream_mode=\"values\"\n",
    "        )\n",
    "        \n",
    "        async for e in events:\n",
    "            if self.config['verbose']: \n",
    "                e[\"messages\"][-1].pretty_print()\n",
    "            response = e[\"messages\"][-1]\n",
    "        \n",
    "        response = response.content\n",
    "        response = utils.format_bot_response(response, markdown=True)\n",
    "        \n",
    "        if self.config['keep_chat_history']:\n",
    "            chat_history = database.chat_history.insert(bot_message=response, human_message=user_input, user_id=user_id)\n",
    "        \n",
    "        if self.config['return_reference']:\n",
    "            return response, get_tools_output()\n",
    "        else:\n",
    "            return response\n",
    "      \n",
    "            \n",
    "    def submit_user_message_with_debug_command(self, *args, **kwargs) -> str:\n",
    "        return self.__with_debug_command(self.submit_user_message)(self, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bot = AgentBot(keep_chat_history=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot.submit_user_message_with_debug_command(\"//reset\", user_id=\"test\")\n",
    "# Bot.submit_user_message_with_debug_command(\"//get chat history\", user_id=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: service\n",
      "\n",
      "\"Hello, I'm Financial Service, a friendly and helpful female virtual assistant. I'm calling today to help update your financial profile. This will allow us to better understand your credit profile and provide you with better services in the future. It will only take a few minutes. May I proceed with the update?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Hello, I\\'m Financial Service, a friendly and helpful female virtual assistant. I\\'m calling today to help update your financial profile. This will allow us to better understand your credit profile and provide you with better services in the future. It will only take a few minutes. May I proceed with the update?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bot.submit_user_message(r\"answer call\", user_id=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
